{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Microtask 3 (Implementing CHAOSS metrics with Perceval idea)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "<p>Produce a notebook with charts showing the distribution of time-to-close for issues already closed, and opened during the last year, for each of the repositories analyzed, and for all of them together. Use Pandas for this, and the Python charting library of your choice (as long as it is a FOSS module).</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving the data\n",
    "\n",
    "<p> For this task, information from the following GitHub repos will be analyzed:</p>\n",
    "<ul>\n",
    "    <li>Perceval (https://github.com/chaoss/grimoirelab-perceval)</li>\n",
    "    <li>SortingHat (https://github.com/chaoss/grimoirelab-sortinghat)</li>\n",
    "    <li>Kibiter (https://github.com/chaoss/grimoirelab-kibiter)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date of retrieval: April 3rd 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> The following commands were executed on terminal to write the retrieved data to the issues.json file:\n",
    "    (XXXX after the -t should be replaced with a valid <a href = \"https://help.github.com/en/articles/creating-a-personal-access-token-for-the-command-line\">GitHub API Token</a>)\n",
    "</p>\n",
    "\n",
    "````\n",
    "perceval github --json-line --category issue grimoirelab perceval --sleep-for-rate -t XXXX > issues.json \n",
    "\n",
    "perceval github --json-line --category issue grimoirelab sortinghat --sleep-for-rate -t XXXX >> issues.json \n",
    "\n",
    "perceval github --json-line --category issue grimoirelab kibiter --sleep-for-rate -t XXXX >> issues.json \n",
    "````\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the data\n",
    "\n",
    "<p>As <a href = \"https://chaoss.github.io/grimoirelab-tutorial/perceval/github.html#retrieving-from-github-with-no-credentials\">Perceval documentation</a> indicates, \"in GitHub every pull request is an issue, but not every issue is a pull request. Thus, the issues returned may contain pull request information (included in the field pull_request within the issue).\"\n",
    "<p>\n",
    "<p> So the next step is just selecting those issues with no \"pull_request\" inside the issue 'data' field </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import datetime\n",
    "from dateutil import parser\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#creating a list of issues which are not pull requests\n",
    "clean_issues = []\n",
    "with open('issues.json') as issues_file:\n",
    "    for line in issues_file:\n",
    "        issue = json.loads(line)\n",
    "        ##if theres no pull_request field, it means is a real issue, so we will add it to our issues list\n",
    "        if ('pull_request' not in issue['data']):\n",
    "            clean_issues.append(issue)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passing the issue's relevant information to a pandas dataframe\n",
    "\n",
    "<p> The next step is to create a pandas dataframe with every single element in clean_issues as a row of it. In order to achieve this, we are going to create a function called summarizeIssue which will take only relevant features(each of these will be a dataframe's column) for the analysis from each issue </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function based on the _summary function from the Code_changes class in the microstask 0 example\n",
    "\n",
    "def summarizeIssue(issue):\n",
    "    '''\n",
    "    This is a function for summarizing issue's relevant information \n",
    "    \n",
    "    Parameters:\n",
    "    issue(dict) : json's file line describing an issue\n",
    "    \n",
    "    Returns:\n",
    "    dict: A non-nested dictionary which can be easily appended as a row of a dataframe\n",
    "    '''\n",
    "    cdata = issue['data']\n",
    "    \n",
    "    ##Adding just the relevant fields from the complete issue\n",
    "    summary = {\n",
    "            'repo': issue['origin'],\n",
    "            'uuid': issue['uuid'],\n",
    "            'author': cdata['user']['login'],\n",
    "            'created_date': datetime.datetime.strptime(cdata['created_at'],\n",
    "                                           \"%Y-%m-%dT%H:%M:%SZ\"),\n",
    "            'closed_date':datetime.datetime.strptime(cdata['closed_at'],\n",
    "                                         \"%Y-%m-%dT%H:%M:%SZ\") if cdata['closed_at'] else None, \n",
    "            'url': cdata['html_url'],\n",
    "            'state':cdata['state']\n",
    "    }\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> The summarizeIssue function will help us to retrieve only important information from each issue </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Creating the pandas dataframe\n",
    "col_names = ['repo', 'uuid', 'author', 'created_date', 'closed_date', 'url','state' ]\n",
    "issues_df = pd.DataFrame(columns = col_names)\n",
    "\n",
    "##adding each issue from the clean_issues list to the issues_df dataframe\n",
    "for issue in clean_issues:\n",
    "    summary = summarizeIssue(issue)\n",
    "    issues_df = issues_df.append(pd.Series(summarizeIssue(issue)), ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting rows from issues which were created and closed in the last year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Since we are going to analyze the distribution of time to close for issues already closed and opened during the last year, we just want to keep in our dataframe the issues which have a 'closed' state and whose create and closed date have 2018 in the year part </p>\n",
    "<p>First we need to change the closed_date column to datetime type so we can be able to manipulate this attribute as a date </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "repo                    object\n",
       "uuid                    object\n",
       "author                  object\n",
       "created_date    datetime64[ns]\n",
       "closed_date             object\n",
       "url                     object\n",
       "state                   object\n",
       "dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issues_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "repo                    object\n",
       "uuid                    object\n",
       "author                  object\n",
       "created_date    datetime64[ns]\n",
       "closed_date     datetime64[ns]\n",
       "url                     object\n",
       "state                   object\n",
       "dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issues_df['closed_date'] = pd.to_datetime(issues_df['closed_date'])\n",
    "issues_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Now lets select the registers to be analyzed. Remember, we just want issues opened and closed last year</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_year = datetime.datetime.now().year - 1\n",
    "last_year_closed_issues = issues_df[(issues_df['created_date'].dt.year == last_year) & (issues_df['closed_date'].dt.year == last_year) & (issues_df['state'] == 'closed')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55, 7)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_year_closed_issues.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
